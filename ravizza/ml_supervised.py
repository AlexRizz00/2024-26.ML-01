# -*- coding: utf-8 -*-
"""ML_Supervised.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EnVC15SdCk1LVlTFTWxqD4scYQyf4OXU
"""

import pandas as pd

#Importa il dataframe

df = pd.read_csv('mushrooms.csv')

df

df.dropna(axis=0, inplace=True) #Elimina le righe con valori nulli

df

"""## Legenda

**Attribute Information (Il nostro Target)**: (classes: **edible**=e, **poisonous**=p)

* **cap-shape**: bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s
* **cap-surface**: fibrous=f,grooves=g,scaly=y,smooth=s
* **cap-color**: brown=n,buff=b,cinnamon=c,gray=g,green=r,pink=p,purple=u,red=e,white=w,yellow=y
* **bruises**: bruises=t,no=f
* **odor**: almond=a,anise=l,creosote=c,fishy=y,foul=f,musty=m,none=n,pungent=p,spicy=s
* **gill-attachment**: attached=a,descending=d,free=f,notched=n
* **gill-spacing**: close=c,crowded=w,distant=d
* **gill-size**: broad=b,narrow=n
* **gill-color**: black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e,white=w,yellow=y
* **stalk-shape**: enlarging=e,tapering=t
* **stalk-root**: bulbous=b,club=c,cup=u,equal=e,rhizomorphs=z,rooted=r,missing=?
* **stalk-surface-above-ring**: fibrous=f,scaly=y,silky=k,smooth=s
* **stalk-surface-below-ring**: fibrous=f,scaly=y,silky=k,smooth=s
* **stalk-color-above-ring**: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y
* **stalk-color-below-ring**: brown=n,buff=b,cinnamon=c,gray=g,orange=o,pink=p,red=e,white=w,yellow=y
* **veil-type**: partial=p,universal=u
* **veil-color**: brown=n,orange=o,white=w,yellow=y
* **ring-number**: none=n,one=o,two=t
* **ring-type**: cobwebby=c,evanescent=e,flaring=f,large=l,none=n,pendant=p,sheathing=s,zone=z
* **spore-print-color**: black=k,brown=n,buff=b,chocolate=h,green=r,orange=o,purple=u,white=w,yellow=y
* **population**: abundant=a,clustered=c,numerous=n,scattered=s,several=v,solitary=y
* **habitat**: grasses=g,leaves=l,meadows=m,paths=p,urban=u,waste=w,woods=d




"""

#Vado a definire le Features e i Labels
X = df[['cap-shape', 'cap-surface','cap-color','bruises']] #Ho selezionato poche features per
                                                           #evitare che il modello sia troppo potente
y = df['class']

#Dimostro le grandezze rispettivamente delle Features e delle Labels
print(X.shape)
print(y.shape)

y

from sklearn.preprocessing import LabelEncoder

#Trasformiamo le nostre Label in numeri codificati
label_encoder = LabelEncoder()
y = pd.Series(label_encoder.fit_transform(df['class']), name='class')

y

#Per evitare l'overfitting, eseguo lo split in Train Set e Test Set del dataframe
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,
                                                    shuffle=True,random_state=42)

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

encoder = ColumnTransformer(
    [
        ('onehot', OneHotEncoder(sparse_output=False), X.columns)
    ],
    remainder='passthrough', #Le colonne non toccate rimarranno invariate
    verbose_feature_names_out=False, #Si evitano nomi lunghi con i prefissi delle
                                     #colonne trasformate
    force_int_remainder_cols=False #Tutte le colonne non specificate dal Column
                                   #transormer non vengono forzosamente convertite
                                   #in int

)

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

#Costruiamo una PipeLine per automare i processi di Encoding, Standardizzazione
#e Classificazione per costruire il nostro modello
pipe = Pipeline(
    [
        ('encoder', encoder), #OneHot Encoding delle nostre Features
        ("scaler", StandardScaler()), #standardizzazione Features per renderle
                                      #di peso uguale sul modello
        ("randFor_cls", RandomForestClassifier(n_estimators=100, random_state=42))
        #Utilizzo dell'algoritmo della Random Forest specializzato nella classificazione
    ]
)

pipe.fit(X_train,y_train) #Training modello

y_test_pred = pipe.predict(X_test) #Facciamo predizioni sull'efficacia del nostro modello

from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay

cm = confusion_matrix(y_test, y_test_pred) #Creiamo una Confusion Matrix per
                                           #verificare l'efficacia del nostro modello

#Evaluazione modello
from sklearn.metrics import accuracy_score

print("Model Accuracy:", accuracy_score(y_test, y_test_pred))

#Visualizziamo la Confusion Matrix del nostro modello

disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()

pipe.get_params() #Visualizziamo gli iper-parametri disponibili

#Per migliorare le prestazioni del modello, eseguiamo una Model Selection
#basata sul Random Search

import numpy as np

param_dist = {
    'randFor_cls__n_estimators': np.arange(50, 300, 50),  # Numero di alberi
    'randFor_cls__max_depth': np.arange(3, 15, 3),  # Profondità di ciascun albero
    'randFor_cls__min_samples_split': [2, 5, 10],  # Numero minimo di sample per dividere un nodo
    'randFor_cls__criterion': ['gini', 'entropy'],  # Criterio di Splitting
}

#Creiamoci il nostro Modello di Model Selection
from sklearn.model_selection import RandomizedSearchCV, KFold

random_search = RandomizedSearchCV(
    estimator=pipe,
    param_distributions=param_dist,
    n_iter=20,  # Numero di tentativi
    cv=KFold(n_splits=5, shuffle=True, random_state=42),  # 5-fold cross-validation
    scoring='accuracy',  # Ottimizzazione per l'Accuratezza della Classificazione
    verbose=4,
    refit=True #Addestra automaticamente il Modello con i Migliori Iper-parametri
)

random_search.fit(X_train, y_train) #Addestriamo il modello di Model Selection

best_model = random_search.best_estimator_ #Usiamo il nostro Modello con i migliori
                                           #Iper-Parametri
y_best_pred = best_model.predict(X_test) #Previsione modello ottimizzato

#Evaluazione modello
from sklearn.metrics import accuracy_score

print("Normal Model Accuracy:", accuracy_score(y_test, y_test_pred)) #Modello Normale
print("Best Model Accuracy:", accuracy_score(y_test, y_best_pred)) #Modello Ottimizzato

from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay

cm = confusion_matrix(y_test, y_best_pred) #Creiamo una Confusion Matrix per
                                           #verificare l'efficacia del nostro
                                           #Modello Ottimizzato

#Visualizziamo la Confusion Matrix del nostro Modello Ottimizzato

disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()

"""Si nota che la differenza tra il Modello Normale e il Modello Ottimizzato è risibile per la semplicità del nostro Modello (4 Target e una classificazione Binaria da predirre)"""